# deep learning software

## CPU vs GPU
- CPU: fewer cores, but each thread is faster and capable, great for sequential tasks.
    - memory: cache and system RAM
- GPU: more cores, but each core is slower and weaker, great for parallel tasks(do similar things, cores work together).
    - memory: cache, own RAM
- matrix multiplication: vectorized computation, GPU works better in throughput.
- programming GPUs
    - CUDA: C-like code but cares caches management and branches, makes it hard to write nice code. Higher-level APIs(computational primitives): cuBLAS(matrix multiplication, ...), cuFFT, cnDNN(CNN propagation, batch normalization), etc.
    - OpenCL: runs on anything, slower.
    - learn parallel programming: not necessary(like CUDA code), just existing libraries.
- comparision: about 70X faster, but fairness depends on benchmark, level of hardware, and so on.
- cuDNN is about 3X faster than your "unoptimized" CUDA code
- communication: model is in GPU, data is in disk(SSD faster)/RAM (small dataset). You can use multiple CPU threads to prefetch data for GPU.

## deep learning frameworks
- reason
    1. easily build big computational graphs
    2. easily compute gradients
    3. run efficiently in GPU(details)
- TensorFlow: static computational graph
    - `import np, tf`
    - define computational graph, run the graph many times
        ```py
        ''' CPU '''
        x,y,w1,w2=tf.placeholder(tf.float32, shape=(N,D)) # set input slots
        h=tf.maximum(tf.matmul(...)...) # forward pass
        init=tf.contrib.layers.xavier_initializer()
        h=tf.layers.dense(inputs=x,units=H,activation=tf.nn.relu,kernel_initializer=init)
        loss=tf.losses.mean_squared_error(y_pred,y)
        grad_w1, grad_w2=tf.gradients(loss, [w1,w2]) # compute gradients
        with tf.Session() as sess: # enter Session() to run training
            values={x:np.random.randn(N,D),w1=...} # want np arrays as data
            learning_rate=1e-5
            for t in range(50):
                out=sess.run([loss,grad_w1,grad_w2],feed_dict=values)
                loss_val,grad_w1_val,grad_w2_val=out # one epoch
                values[w1]-=learning_rate*grad_w1_val # update gradient, same as w2

        ''' GPU '''
        w1,w2=tf.Variable(tf.random_normal(D,H)) # set variable that holds in graph(GPU doesn't need transform to numpy by CPU)
        # forward pass, compute gradients

        # update variables outside Session(), in graph see as dummy node.
        new_w1=w1.assign(w1-learning_rate*grad_w1)
        updates=tf.group(new_w1,new_w2) # 1
        optimizer=tf.train.GradientDescentOptimizer(1e-5)
        updates=optimizer.minimize(loss) # 2

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer()) # initialize w1,w2
            values={x:,y:}
            for t in range(50):
                loss_val,_=sess.run([loss,updates],feed_dict=values) #only input x,y because w1,w2 exists in graph
        ```
    - Keras: high-level wrapper, on top of TensorFlow
        ```py
        from keras.models import Sequential
        from keras.layers.core import Dense,Activation
        from keras.optimizers import SGD
        model=Sequential()
        model.add(Dense(D,H))
        model.add(Activation('relu'))
        optimizer=SGD(1e0)
        model.compile(loss=,optimizer=)
        history-model.fit(x,y,np_epoch=,batch_size=,verbose=)
        ```
    - Tensorboard: visualize loss and so on when training
    - distributed version
- Pytorch
    - Tensor: like ndarray, but can run on GPU
    - Variable: node in computational graph, stores data and gradient
        - `x` is variable, `x.data` is a Tensor, `x.grad` is variable, `x.grad.data` is Tensor
        - has same API like tensor
        ```py
        import torch
        from torch.autograd import Variable
        # 1. tensor type
        dtype=torch.FloatTensor # run on CPU
        dtype=torch.cuda.FloatTensor # run on GPU
        x=torch.randn(N,D_in).type(dtype)
        # 2. variable type
        x=Variable(torch.randn(N,D_in),requires_grad=False)
        w1=Variable(torch.randn(H,D_out),requires_grad=True)
        learning_rate=1e-6
        for t in range(500):
            relu=ReLU()
            y_pred=relu(...) # own autograd functions
            h=x.mm(w1) h.clamp(min=) h.pow h.sum x.t() # forward pass
            # 1. compute gradients manually
            grad_h=h.clone()*...
            w1-=learning_rate*grad_w1
            # 2. autograd(need Variable)
            if w1.grad: w1.grad.data.zero()
            loss.backward()
            w1.data-=learning_rate*w1.grad.data

        # 2. define autograd functions
        class ReLU(torch.aurograd.Function):
            def forward(self,x):
                self.save_for_backward(x)
                return x.clamp(min=0)
            def backward(self,grad_y):
                x,=self.saved_tensors
                grad_input=grad_y.clone()
                grad_input[x<0]=0
                return grad_input
        ```
    - module: nn layer(means high-level), may store state/weights
        ```py
        # define variables...
        model=torch.nn.Sequential(
            torch.nn.Linear(D_in,H),
            torch.nn.ReLU(),
            torch.nn.linear(H,D_out))
        loss_fn=torch.nn.MSELoss(size_average=False)
        # 1. normal optimize (nothing)
        # 2. use optimizer
        optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)
        for t in range(500):
            y_pred=model(x)
            loss=loss_fn(y_pred,y)
            # 1. normal optimize
            model.zero_grad()
            loss.backward()
            for param in model.parameters():
                param.data-=learning_rate*param.grad.data
            # 2. use optimizer
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        ```
    - define new modules
        - inputs and outputs are Variables
        - can contain weights/other modules
        ```py
        class TwoLayerNet(torch.nn.Module):
            def __init__(self,D_in,H,D_out):
                super(TwoLayerNet,self).__init__()
                self.linear1=torch.nn.Linear(...)
            def forward(self,x):
                y_pred=self.linear2(...)
                return y_pred
            # backward will be handled by autograd!

        model=TwoLayerNet(D_in,H,D_out)
        ```
    - DataLoader: provide minibatching, shuffling, multithreading. You can write own Dataset class for custom data
        ```py
        from torch.utils.data import TensorDataset,DataLoader
        loader=DataLoader(TensorDataset(x,y),batch_size=8) # after define x,y
        for epoch in range(10): # minibatch
            for x_batch,y_batch in loader: # Loader returns Tensors
                x_var,y_var=Variable(x),Variable(y)
                # others are the same as `for t in range(500)`
        ```
    - pretrained models:`alexnet=torchvision.models.alexnet(pretrained=True) # vgg16, resnet101, etc.`
    - Visdom: a vision board like TensorBoard
    - use dynamic computational graph(build graph in each iteration).
        - Static graph can be optimized better than dynamic one.
        - Static graph can serialize and run without code next time(put graph to memory/disk).
        - Dynamic graph is good at condition/loop using python control flow, while static one use specific manners.
        - Dynamic graph application: recurrent networks, recursive networks, modular networks
- Caffe
    - no need to write code(but use script, prototxt)
    - not popular in research, but in production(Caffe2)
